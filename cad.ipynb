{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a9e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.3.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Downloading numpy-2.3.1-cp312-cp312-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/12.7 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.9/12.7 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.8/12.7 MB 12.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.2/12.7 MB 13.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.7 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 12.5 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mpip\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minstall numpy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  # This command only in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a8ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get project files\n",
    "!wget https://cdn.freecodecamp.org/project-data/cats-and-dogs/cats_and_dogs.zip\n",
    "\n",
    "!unzip cats_and_dogs.zip\n",
    "\n",
    "PATH = 'cats_and_dogs'\n",
    "\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')\n",
    "test_dir = os.path.join(PATH, 'test')\n",
    "\n",
    "# Get number of files in each directory. The train and validation directories\n",
    "# each have the subdirecories \"dogs\" and \"cats\".\n",
    "total_train = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
    "total_val = sum([len(files) for r, d, files in os.walk(validation_dir)])\n",
    "total_test = len(os.listdir(test_dir))\n",
    "\n",
    "# Variables for pre-processing and training.\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767d9b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 3\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_data_gen = validation_image_generator.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Move all test images into a subfolder \"unknown\" (only needed once)\n",
    "import shutil\n",
    "\n",
    "test_unknown_dir = os.path.join(test_dir, 'unknown')\n",
    "os.makedirs(test_unknown_dir, exist_ok=True)\n",
    "\n",
    "# Move test images into the \"unknown\" folder (only if not already moved)\n",
    "if len(os.listdir(test_unknown_dir)) == 0:\n",
    "    for fname in os.listdir(test_dir):\n",
    "        fpath = os.path.join(test_dir, fname)\n",
    "        if os.path.isfile(fpath):\n",
    "            shutil.move(fpath, test_unknown_dir)\n",
    "\n",
    "test_data_gen = test_image_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ba619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "def plotImages(images_arr, probabilities = False):\n",
    "    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5,len(images_arr) * 3))\n",
    "    if probabilities is False:\n",
    "      for img, ax in zip( images_arr, axes):\n",
    "          ax.imshow(img)\n",
    "          ax.axis('off')\n",
    "    else:\n",
    "      for img, probability, ax in zip( images_arr, probabilities, axes):\n",
    "          ax.imshow(img)\n",
    "          ax.axis('off')\n",
    "          if probability > 0.5:\n",
    "              ax.set_title(\"%.2f\" % (probability*100) + \"% dog\")\n",
    "          else:\n",
    "              ax.set_title(\"%.2f\" % ((1-probability)*100) + \"% cat\")\n",
    "    plt.show()\n",
    "\n",
    "sample_training_images, _ = next(train_data_gen)\n",
    "plotImages(sample_training_images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b6df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "train_image_generator = ImageDataGenerator(\n",
    "    rescale=1./255,             # Normalize pixel values (always needed)\n",
    "    rotation_range=40,          # Randomly rotate images up to 40 degrees\n",
    "    width_shift_range=0.2,      # Randomly shift images horizontally\n",
    "    height_shift_range=0.2,     # Randomly shift images vertically\n",
    "    shear_range=0.2,            # Shear transformation\n",
    "    zoom_range=0.2,             # Random zoom in/out\n",
    "    horizontal_flip=True,       # Randomly flip images horizontally\n",
    "    fill_mode='nearest'         # Fill in any empty pixels after transforms\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c80f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=train_dir,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='binary')\n",
    "\n",
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32774d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=train_data_gen.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=val_data_gen.samples // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c28bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_gen.reset()\n",
    "predictions = model.predict(test_data_gen)\n",
    "probabilities = [1 if p > 0.5 else 0 for p in predictions]\n",
    "\n",
    "test_images = [test_data_gen[i][0][0] for i in range(len(probabilities))]\n",
    "plotImages(test_images, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1dd847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If provided, use the project's built-in checker:\n",
    "# For example:\n",
    "# check_accuracy(predictions)\n",
    "\n",
    "# Or, just manually confirm you’ve reached 63%+ accuracy in training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
